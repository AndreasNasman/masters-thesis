\bgroup{}

\chapter{Background}\label{cha:background}
In the first part of this chapter, the content provides more background on the topic and exhibits the current state of the subject. The second section briefly presents associated literature and how it relates to the proposition in this thesis.

\section{Problem description}
The art of sound design involves planning, creating, and acquiring sounds destined for media productions or other purposes~\cite[1]{rep:knowledge_and_content-based_audio_retrieval_using_wordnet}. Skillfully implemented audio integrates so tightly with other content forms, such as video and animation, that it often goes unnoticed~\cite[1]{rep:an_approach_for_structuring_sound_sample_libraries_using_ontology}. Sound is nevertheless a vital part of audiovisual production – movies, games, television programs, and the like – where up to 75 \% of the \glspl{sfx} are part of the post-production stage~\cite[1]{rep:extending_tagging_ontologies_with_domain_specific_knowledge}.

In general terms, there are two ways of obtaining samples of sound. The first approach is to reconstruct audio using objects that imitate the wanted sound. The props used in this routine, called \emph{foley}, can be anything able to mimic the sonic properties of the desired sample~\cite[1]{rep:unsupervised_taxonomy_of_sound_effects}. A sound designer can also generate sounds electronically for specific purposes, where programs can assist in the creation process~\cite{rep:machine_learning_and_sound_design}. These composition methods can be quite tedious and expensive since the sound producer needs time and resources when creating audio from scratch.

The second approach has the sound designer using sound libraries containing various predefined example sounds. These \glspl{sfx} libraries can contain thousands of sounds, often with variations of a particular sound through changes in intensity, material, duration, or similar. By mixing the sounds, the designer is also able to blend tracks to create new samples in endless combinations. This possibility can be particularly useful to, e.g., increase the dramatic effect of a sound.~\cite[1]{rep:an_approach_for_structuring_sound_sample_libraries_using_ontology}~\cite[1]{rep:knowledge_and_content-based_audio_retrieval_using_wordnet}

Using sound libraries is not problem-free; it has challenges and complications. One of the predominant issues is the lack of a standardized taxonomy and universally agreed on vocabulary. Constructing and cataloging the libraries is also tiresome and error-prone~\cite[1]{rep:knowledge_and_content-based_audio_retrieval_using_wordnet}. These disadvantages make it challenging to develop navigation systems for managing the sounds, which the sound designers need due to the sheer size of the data handled. Sound designers are also more interested in the sonic properties of a sound than the physical properties. Still, most of the categorization systems organize the sounds into geographical or physical categories.~\cite[1]{rep:unsupervised_taxonomy_of_sound_effects}

A common aspect neglected in the sound libraries themselves and the supplementing tools is the absence of support for private annotation and subjective queries. Humans often describe sound with personal and biased words, which hints at the notion of a system adjustable for every individual being beneficial~\cite[8]{rep:an_approach_for_structuring_sound_sample_libraries_using_ontology}. However, implementing subjective tags is a problematic task. Subjectivity, by its nature, varies among people, making it impossible to create collective terms acceptable by everyone. On the contrary, if a system focused on each individual and adapted to the current operator and circumstances, it could produce better results. This inquest is the centerpiece of this thesis and what the author tries to solve with the proposed system.

\section{Related work}
The author has found no prior immediately similar or comparable work related to the proposed solution outlined in \cref{sec:motive} and further discussed in this thesis. Personal sound classification using subjective tags seems to be uncommon, as most previous studies focus on the mass and commonality while trying to establish universal audio categorization systems. Nonetheless, some related topics that the suggested system resembles have inspired extensive research and produced prominent content to a large extent.

Studies have concluded in the area of automatic sound identification and annotation of audio in great detail. These researches cover both fully automatic procedures by the computer alone, and semi-automatic methods were both humans and machines operate in conjunction.~\cite{rep:morphological_sound_description_computational_model_and_usability_evaluation} shows a fully automatic approach to extract perceptual labels with reliable accuracy, and the more recent study in~\cite{rep:unsupervised_taxonomy_of_sound_effects} describes a taxonomy based solely on the sonic properties of audio using feature selection, unsupervised learning, and hierarchical clustering. The results in~\cite{rep:identification_of_perceptual_qualities_in_textural_sounds_using_the_repertory_grid_method} and~\cite{rep:on_automated_annotation_of_acousmatic_music} prove that human input, together with the appropriate algorithms, can be of great use to develop high-quality systems. Freesound and Google have launched large scale projects where everyone can help to develop automatic sound recognition by manually listening to and tagging sounds, thus generating correctly labeled training data for machines to utilize~\cite{freesound:annotator, google:audioset}.

Query methods in sound retrieval used for sound libraries are often text-based solutions formed on an ontology. The procedure for finding relevant sounds often searches for verbal descriptions associated with the sounds, e.g., the system developed in~\cite{rep:ecrins_an_audiocontent_description_environment_for_sound_samples}. The textual verbs are usually definitions of sound itself, the sounding situation, or the sound impression~\cite{rep:sound_retrieval_with_intuitive_verbal_descriptions}. These solutions inherit the imprecision and ambiguity problems of natural languages. This issue means that things like polysemy – where a single word can refer to multiple things – and synonymy pollute the systems~\cite[2]{rep:knowledge_and_content-based_audio_retrieval_using_wordnet}. To remedy these problems, presented solutions like~\cite{rep:knowledge_and_content-based_audio_retrieval_using_wordnet},~\cite{rep:constructing_high-level_perceptual_audio_descriptors_for_textural_sounds}, and~\cite{rep:nearest-neighbor_automatic_sound_annotation_with_a_wordnet_taxonomy} adapt semantic networks, say WordNet~\cite{rep:wordnet_an_electronic_lexical_database}, to create relationships and connections between words, and eliminate language-specific uncertainties. Newer studies examine the possibility of including concepts such as domain-specific class definitions and relations~\cite{rep:extending_tagging_ontologies_with_domain_specific_knowledge}, as well as knowledge elicitation and sound design ontology engineering as alternatives or extensions to the traditional text-based retrieval systems~\cite{rep:an_approach_for_structuring_sound_sample_libraries_using_ontology}.

Typical for all of these systems is that they try to improve identification, annotation, and categorization of sounds, often in the context of sound libraries. People making use of sound libraries, e.g., sound designers, can take advantage of and benefit from the advancements. These goals also hold for the proposed system treated in this thesis, although the approach taken to achieve the intention varies slightly.

\egroup{}